
================================================================================
â˜ï¸ CLOUD SEGMENTATION PROJECT - COMPLETE GUIDE
================================================================================
Last Updated: January 12, 2026
Total Size: 415 MB
Location: Google Drive / CLOUD_SEG_COMPLETE

================================================================================
ğŸ“ COMPLETE PATH STRUCTURE
================================================================================

CLOUD_SEG_COMPLETE/
â”‚
â”œâ”€â”€ README.md                    â† Start here (project overview)
â”œâ”€â”€ QUICK_REFERENCE.md           â† Cheat sheet
â”‚
â”‚
â”œâ”€â”€ 01_SEGMENTATION_binary_cloud_vs_sky/     [269 MB] â­ MAIN TASK
â”‚   â”‚
â”‚   â”œâ”€â”€ raw_data/                            [264 MB] RAW IMAGES
â”‚   â”‚   â”œâ”€â”€ HYTA/                            32 images, variable resolution
â”‚   â”‚   â”‚   â”œâ”€â”€ images/                      Sky photos
â”‚   â”‚   â”‚   â””â”€â”€ masks/                       Binary masks (white=cloud)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Almeria/                         770 images, 512Ã—512
â”‚   â”‚   â”‚   â”œâ”€â”€ images/                      Dark sky photos
â”‚   â”‚   â”‚   â””â”€â”€ masks/                       0=ignore, 1=sky, 2+=cloud
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ SWIMSEG-2/                       1,013 images, 600Ã—600
â”‚   â”‚       â”œâ”€â”€ images/                      Bright sky photos
â”‚   â”‚       â””â”€â”€ GTmaps/                      âš ï¸ INVERTED: 0=cloud, 255=sky
â”‚   â”‚
â”‚   â”œâ”€â”€ unified_dataset/                     [1 MB] MANIFESTS
â”‚   â”‚   â”œâ”€â”€ manifest_1815_images_binary.json      All paths for binary seg
â”‚   â”‚   â””â”€â”€ manifest_1815_images_multiclass.json  All paths for multiclass
â”‚   â”‚
â”‚   â”œâ”€â”€ eda_analysis/                        [2.5 MB] EDA RESULTS
â”‚   â”‚   â”œâ”€â”€ eda_all_1815_images_stats.json   â­ FULL STATS (load this!)
â”‚   â”‚   â”œâ”€â”€ viz_distributions_by_source.png  Distribution plots
â”‚   â”‚   â””â”€â”€ viz_summary_statistics.png       Summary stats
â”‚   â”‚
â”‚   â”œâ”€â”€ domain_analysis/                     [0.9 MB] DOMAIN SHIFT
â”‚   â”‚   â”œâ”€â”€ umap_feature_space_clusters.png  Shows ALMERIA is different
â”‚   â”‚   â”œâ”€â”€ umap_coordinates_and_outliers.json   Outlier list
â”‚   â”‚   â””â”€â”€ fft_frequency_signatures_by_source.png
â”‚   â”‚
â”‚   â”œâ”€â”€ label_quality/                       [0.3 MB] BAD LABELS
â”‚   â”‚   â”œâ”€â”€ suspicious_samples_185_flagged.json  â­ INSPECT THESE!
â”‚   â”‚   â””â”€â”€ cleanlab_confidence_distribution.png
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                              [empty] FOR YOUR TRAINED MODELS
â”‚   â””â”€â”€ code/                                [empty] Symlink to 06_CODE
â”‚
â”‚
â”œâ”€â”€ 02_CLASSIFICATION_cloud_types_7class/    [<1 MB] COMPLETED BASELINE
â”‚   â”œâ”€â”€ EXPERIMENT_SUMMARY.json              Results: 60% max with RF
â”‚   â””â”€â”€ README.md                            Details + next steps
â”‚
â”‚
â”œâ”€â”€ 03_DOMAIN_ADAPTATION_cross_camera/       [1 MB] PROBLEM ANALYSIS
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ DOMAIN_SHIFT_ANALYSIS.json       â­ Key finding: ALMERIA different
â”‚       â”œâ”€â”€ umap_shows_ALMERIA_separate.png  Visual proof
â”‚       â””â”€â”€ fft_different_frequency_signatures.png
â”‚
â”‚
â”œâ”€â”€ 04_SAM_EXPERIMENTS_segment_anything/     [143 MB] SAM WEIGHTS
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ sam_decoder_epoch_02.pth         48 MB - Early, least overfit
â”‚   â”‚   â”œâ”€â”€ sam_decoder_epoch_06.pth         48 MB - Second best
â”‚   â”‚   â”œâ”€â”€ sam_decoder_epoch_10.pth         48 MB - â­ BEST (49.2% IoU)
â”‚   â”‚   â”œâ”€â”€ evaluation_results.json          Cross-dataset IoU scores
â”‚   â”‚   â”œâ”€â”€ training_history.json            Loss curves
â”‚   â”‚   â””â”€â”€ README.md                        Explains each weight
â”‚   â””â”€â”€ results/
â”‚       â””â”€â”€ SAM_EXPERIMENT_SUMMARY.json      Why SAM failed
â”‚
â”‚
â”œâ”€â”€ 05_DOCUMENTATION/                        [2 MB] ALL FIGURES
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ fig_01_eda_distributions.png
â”‚   â”‚   â”œâ”€â”€ fig_02_eda_summary_stats.png
â”‚   â”‚   â”œâ”€â”€ fig_03_fft_frequency_analysis.png
â”‚   â”‚   â”œâ”€â”€ fig_04_umap_feature_clusters.png
â”‚   â”‚   â””â”€â”€ fig_05_label_quality_cleanlab.png
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ *.md, *.json                     Old analysis reports
â”‚
â”‚
â””â”€â”€ 06_CODE/                                 [<1 MB] ALL SOURCE CODE
    â”œâ”€â”€ training/
    â”‚   â”œâ”€â”€ training_utils.py                â­ K-fold, Dataset class
    â”‚   â””â”€â”€ data_loader.py                   â­ Path conversion
    â”œâ”€â”€ analysis_tools/
    â”‚   â””â”€â”€ dataset_analysis.py              FFT, UMAP tools
    â””â”€â”€ preprocessing/
        â”œâ”€â”€ lossless_preprocessing.py
        â””â”€â”€ smart_preprocessing_v3.py


================================================================================
ğŸ¯ WHAT TO USE FOR EACH TASK
================================================================================

TASK: Train segmentation model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Load EDA:    01_SEGMENTATION/eda_analysis/eda_all_1815_images_stats.json
2. Get splits:  06_CODE/training/training_utils.py â†’ get_stratified_kfold_splits()
3. Load data:   06_CODE/training/training_utils.py â†’ CloudSegDataset class
4. Images at:   01_SEGMENTATION/raw_data/{HYTA,Almeria,SWIMSEG-2}/

TASK: Check suspicious labels before training
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Open:        01_SEGMENTATION/label_quality/suspicious_samples_185_flagged.json
2. Look at top 30 entries
3. Visually check those images in raw_data/

TASK: Understand domain shift problem
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Read:        03_DOMAIN_ADAPTATION/analysis/DOMAIN_SHIFT_ANALYSIS.json
2. See visual:  03_DOMAIN_ADAPTATION/analysis/umap_shows_ALMERIA_separate.png
3. Key: ALMERIA is completely different from HYTA/SWIMSEG

TASK: Use SAM weights
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Best weight: 04_SAM_EXPERIMENTS/checkpoints/sam_decoder_epoch_10.pth
2. Load with:   torch.load('sam_decoder_epoch_10.pth')
3. Note: These are DECODER weights only, need SAM encoder separately

TASK: Run k-fold training
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```python
from training_utils import load_eda_data, get_stratified_kfold_splits

images, masks = load_eda_data('01_SEGMENTATION/eda_analysis/eda_all_1815_images_stats.json')
splits = get_stratified_kfold_splits(images, masks, n_splits=5)

for split in splits:
    train_idx = split['train_idx']
    val_idx = split['val_idx']
    # Create datasets and train
```


================================================================================
âš ï¸ CRITICAL THINGS TO REMEMBER
================================================================================

1. MASK FORMATS ARE DIFFERENT PER SOURCE!
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   HYTA:    mask > 0 â†’ cloud (simple)
   ALMERIA: 0=ignore, 1=sky, 2+=cloud (need to handle ignore)
   SWIMSEG: 0=cloud, 255=sky (INVERTED!)
   
   Use: convert_mask_to_binary(mask, source) from training_utils.py

2. ALMERIA IS A DIFFERENT DOMAIN
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - UMAP distance: 15+ (vs 0.59 between HYTA/SWIMSEG)
   - Brightness: 41 (vs 123-148 for others)
   - R/B ratio: 0.99 gray (vs 0.68 blue for others)
   - Action: Use domain-balanced batches or train separately

3. 185 SUSPICIOUS LABELS EXIST
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - 37% of sampled images have low confidence
   - 50% from ALMERIA, 44% from SWIMSEG
   - Inspect before training!

4. UPDATE PATHS BEFORE USE
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Edit: 06_CODE/training/data_loader.py
   Change: MAC_PREFIX = '/your/actual/path/...'


================================================================================
ğŸš€ STEP-BY-STEP: SETUP ON MAC SERVER
================================================================================

Step 1: Download from Google Drive
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Go to drive.google.com
- Find folder: CLOUD_SEG_COMPLETE
- Right-click â†’ Download (will be ~415 MB zip)
- Unzip to: /Users/YOUR_NAME/projects/CLOUD_SEG_COMPLETE/

Step 2: Install dependencies
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cd /Users/YOUR_NAME/projects/CLOUD_SEG_COMPLETE
pip install numpy opencv-python torch torchvision scikit-learn albumentations matplotlib tqdm

Step 3: Update paths
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Open: 06_CODE/training/data_loader.py
Find line: MAC_PREFIX = '/Users/YOUR_USERNAME/...'
Change to your actual path

Step 4: Test setup
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python3 -c "
import json
import sys
sys.path.append('06_CODE/training')
from training_utils import load_eda_data, get_stratified_kfold_splits

images, masks = load_eda_data('01_SEGMENTATION_binary_cloud_vs_sky/eda_analysis/eda_all_1815_images_stats.json')
print(f'Loaded {len(images)} images')

splits = get_stratified_kfold_splits(images, masks)
print(f'Created {len(splits)} folds')
print('âœ“ Setup OK!')
"

Step 5: Inspect suspicious labels (IMPORTANT!)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python3 -c "
import json
with open('01_SEGMENTATION_binary_cloud_vs_sky/label_quality/suspicious_samples_185_flagged.json') as f:
    data = json.load(f)
print('Top 10 suspicious samples:')
for item in data['top_issues'][:10]:
    print(f"  {item['rank']}. {item['path'].split('/')[-1]} - {item['source']}")
    print(f"     Cloud: {item['cloud_ratio']:.1%}, Predicted: {item['predicted_label']}")
"

Step 6: Start training
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Your training script here
# Use CloudSegDataset from training_utils.py
# Use get_domain_balanced_weights() to handle ALMERIA


================================================================================
ğŸ“Š KEY NUMBERS TO REMEMBER
================================================================================

Total images:        1,815
â”œâ”€â”€ HYTA:            32   (bright, blue sky)
â”œâ”€â”€ ALMERIA:         770  (dark, gray sky) âš ï¸ DIFFERENT DOMAIN
â””â”€â”€ SWIMSEG:         1,013 (bright, blue sky)

Splits:
â”œâ”€â”€ Train:           1,509
â”œâ”€â”€ Val:             178
â””â”€â”€ Test:            128

Suspicious labels:   185 (37% of sample)
ALMERIA-SWIMSEG gap: 15.17 UMAP distance (HUGE)

Baselines:
â”œâ”€â”€ R/B Otsu:        73% IoU (simple, fast)
â”œâ”€â”€ SAM best:        49% IoU (complex, slow)
â”œâ”€â”€ Classification:  60% max (Random Forest, 7-class)
â””â”€â”€ Cross-dataset:   15-20% (transfer learning fails)


================================================================================
ğŸ“ IF STUCK
================================================================================

1. Check README.md in project root
2. Check QUICK_REFERENCE.md for cheat sheet
3. Check README.md in each subfolder
4. Key insight files:
   - 03_DOMAIN_ADAPTATION/analysis/DOMAIN_SHIFT_ANALYSIS.json
   - 04_SAM_EXPERIMENTS/results/SAM_EXPERIMENT_SUMMARY.json

================================================================================
